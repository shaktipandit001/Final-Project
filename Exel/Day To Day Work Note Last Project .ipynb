{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d54e39",
   "metadata": {},
   "source": [
    "# Daily Work Progress\n",
    "\n",
    "## Day 1 - Last Project of Bootcamp 18.06.2024\n",
    "\n",
    "* Go through the plan and project overview.\n",
    "* <u>Talk with Andre and make a mindset about the steps I need to take and what data I am using.</u>\n",
    "* Set a target for what I would like to achieve with my dataset.\n",
    "* Did not do a lot of work, only thought about and made a mindset about what I need to do.\n",
    "\n",
    "#### Most Difficult Part is Collecting Data\n",
    "\n",
    "## Day 2 - Last Project of Bootcamp 20.06.2024\n",
    "\n",
    "* I am using data from my company, so I need to gather all necessary information.\n",
    "* For my COGS (Cost of Goods Sold) app and forecasting, I require a significant amount of data. I have selected some key data points from our company's website.\n",
    "* Our company utilizes BOOTSTraper (Backoffice) software provided by Samuelson Kassen, a German company specializing in cash handling and offering various functions tailored for food companies.\n",
    "* As part of my plan, I have compiled a list of essential data and included some notes on it.\n",
    "\n",
    "#### Divided into Two Parts:\n",
    "\n",
    "* **COGs Part**:\n",
    "    1. Calculation of all recipes, which I need to do myselfâ€”very time-consuming process.\n",
    "    2. Total product sales: necessary for accurate data calculation.\n",
    "    3. Total goods purchased in 2023.\n",
    "    4. Total goods sales of 2023 (requires recipe calculations).\n",
    "    5. Inventory details for all products made by our company.\n",
    "    6. Total goods list including actual price, article number, article name, supplier, packaging/mass, article category, purchase date, and quantity bought.\n",
    "    7. Waste management data.\n",
    "\n",
    "* **Sales Part for Forecasting**:\n",
    "    1. Daily sales per recipe statistics, detailing multiple important data points.\n",
    "    2. Daily sales throughout the year.\n",
    "    3. Total hours worked by each worker.\n",
    "    4. Total discounts and coupons issued.\n",
    "    5. Daily detailed product sales.\n",
    "    6. Overall daily sales total.\n",
    "\n",
    "# ETL (Extract Transform Load) Process\n",
    "\n",
    "#### Data Collection Part\n",
    "\n",
    "## <u>Data Collected From Braun Food Services GmbH.</u>\n",
    "#### <u>(Samuelson Kassensysteme) - Bootstraper</u>\n",
    "#### <u>Sales Data from 2023 (Real Data)</u>\n",
    "\n",
    "* **COGs Part**:\n",
    "    1. Calculation of all recipes, which I started but found it to be a very time-consuming process (estimated 2-3 weeks). Instead, I decided to create a demo with sample data to showcase its impact on other affected data.\n",
    "    2. Total product sales: extracted from the company's STastic or Umsastzt (Sales File).\n",
    "    3. Total goods purchased in 2023: received monthly from our Goods Sales Department, ensuring it is current and accurate.\n",
    "    4. Total goods sales of 2023: I created a demo version with approximate figures since full data requires recipes.\n",
    "    5. Inventory details for all products made by our company: obtained monthly from our Store Manager.\n",
    "    6. Total goods list including actual price, article number, article name, supplier, packaging/mass, article category, purchase date, and quantity bought: updated monthly from our Goods Sales Department.\n",
    "    7. Waste management data: provided demo data for waste and lost or stolen items combined into one category.\n",
    "\n",
    "* **Sales Part for Forecasting**:\n",
    "    1. Daily sales per recipe statistics: sourced from the company's Backoffice.\n",
    "    2. Daily sales throughout the year: extracted from the company's Backoffice. Split into 6 parts due to download restrictions.\n",
    "    3. Total hours worked by each worker: retrieved from the company's Backoffice.\n",
    "    4. Total discounts and coupons issued: data collected from the company's Backoffice.\n",
    "    5. Daily detailed product sales: obtained from the company's Backoffice.\n",
    "    6. Overall daily sales total: obtained from the company's Backoffice.\n",
    "\n",
    "### I collected 18 Excel files for my work\n",
    "\n",
    "### Reviewing The Data Display\n",
    "\n",
    "* I am going through every piece of data orally, and I've discovered that it's very extensive. I'll need to filter through all of it.\n",
    "* Upon review, I've decided to omit the Daily sales throughout the year, which was extracted from the company's Backoffice and split into 6 parts due to download restrictions. Instead, I'll use the Overall Daily sales, which contains the same data with slight differences that won't affect anything, so I've chosen not to include it.\n",
    "* Therefore, I am ignoring the Price List, as it is unnecessary for my needs.\n",
    "* I am also ignoring the List of Goods for Purchase because it is already included in the Total Buying of Goods.\n",
    "\n",
    "### This means I now have only 8 Excel files for my work.\n",
    "\n",
    "#### <u> Andre's Tips to Merge All Data and Preprocess It </u>\n",
    "\n",
    "* I am merging and uploading Excel data, and the dataset looks very messy. So, I have delved deeper into the dataset and removed all columns from each Excel file that do not have any value and are not necessary for me. This is because merging it caused the data to become messy. I spent almost the whole night preprocessing all the data once more in Excel. Now, I'm excited for the next day.\n",
    "\n",
    "\n",
    "## Day 3 - Last Project of Bootcamp 22.06.2024\n",
    "* When I started To Merge it Takes a lot of time and brak Down in Middel. \n",
    "* Error That I Got \n",
    "##### emoryError: Unable to allocate 5.27 GiB for an array with shape (13, 54419652) and data type float64\n",
    "* I got This Error while Merging 4 File.\n",
    "* next I am merging only 2 File also get Error.\n",
    "* Error That I Got  Next\n",
    "##### MemoryError: Unable to allocate 1.23 GiB for an array with shape (9, 18364725) and data type float64\n",
    "\n",
    "#### <u> Andre's introduce me New Library Called Polar </u>\n",
    "\n",
    "* I need To Go Through Documntation of Polar So I can shout the Merging Trouble.\n",
    "\n",
    "\n",
    "## Polars Library in Python\n",
    "\n",
    "### Overview\n",
    "Polars is a high-performance DataFrame library for Python, optimized for large datasets and efficient data manipulation.\n",
    "\n",
    "### Key Features\n",
    "- **High Performance**: Utilizes multi-threading and SIMD for fast data processing with low memory usage.\n",
    "- **DataFrame Operations**:\n",
    "  - **Lazy Evaluation**: Defers execution to optimize performance.\n",
    "  - **Eager Evaluation**: Executes operations immediately, similar to pandas.\n",
    "  - **Streaming**: Processes large datasets in chunks to handle memory constraints.\n",
    "- **User-Friendly API**: Intuitive and similar to pandas, making it easy for users to adopt.\n",
    "- **Interoperability**: Compatible with pandas and integrates well with other data processing libraries.\n",
    "\n",
    "### Benefits\n",
    "- **Speed**: Designed to be significantly faster than pandas.\n",
    "- **Efficiency**: Handles large datasets with efficient memory usage.\n",
    "- **Flexibility**: Supports complex data manipulation and queries.\n",
    "\n",
    "Polars offers a powerful alternative to pandas, focusing on performance and scalability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5acf13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
